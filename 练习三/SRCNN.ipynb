{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8202a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理 `E:\\jupyter\\three\\data\\Set5\\baby.png`...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19676\\.conda\\envs\\py38\\lib\\site-packages\\torchvision\\transforms\\transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sr_y_image (512, 512, 1)\n",
      "hr_y_image (512, 512, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 252\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPSNR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_psnr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [dB]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSIM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_ssim\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [u]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 252\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 233\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msr_y_image\u001b[39m\u001b[38;5;124m\"\u001b[39m, sr_y_image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhr_y_image\u001b[39m\u001b[38;5;124m\"\u001b[39m, hr_y_image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 233\u001b[0m ssim_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mstructural_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43msr_y_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_y_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgaussian_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mmultichannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# 将所有图像的PSNR和SSIM指标加起来，计算平均值\u001b[39;00m\n\u001b[0;32m    236\u001b[0m psnr_metrics_all \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m psnr_metrics\n",
      "File \u001b[1;32m~\\.conda\\envs\\py38\\lib\\site-packages\\skimage\\metrics\\_structural_similarity.py:178\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[1;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m         win_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m   \u001b[38;5;66;03m# backwards compatibility\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((np\u001b[38;5;241m.\u001b[39masarray(im1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m win_size) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin_size exceeds image extent. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither ensure that your images are \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least 7x7; or pass win_size explicitly \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min the function call, with an odd value \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless than or equal to the smaller side of your \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages. If your images are multichannel \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(with color channels), set channel_axis to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe axis number corresponding to the channels.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (win_size \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindow size must be odd.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from natsort import natsorted\n",
    "from torchvision.transforms import functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "from skimage.metrics import structural_similarity\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(SRCNN, self).__init__()\n",
    "\n",
    "        # 定义模型的卷积层\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, (9, 9), (1, 1), (4, 4)),  # 输入通道数为1，输出通道数为64，卷积核大小为9x9，步长为1，填充为4\n",
    "            nn.ReLU(True)  # ReLU激活函数\n",
    "        )\n",
    "\n",
    "        self.map = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, (5, 5), (1, 1), (2, 2)),  # 输入通道数为64，输出通道数为32，卷积核大小为5x5，步长为1，填充为2\n",
    "            nn.ReLU(True)  # ReLU激活函数\n",
    "        )\n",
    "\n",
    "        self.reconstruction = nn.Conv2d(32, 1, (5, 5), (1, 1), (2, 2))  # 输入通道数为32，输出通道数为1，卷积核大小为5x5，步长为1，填充为2\n",
    "\n",
    "        self._initialize_weights()  # 初始化网络权重\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self._forward_impl(x)  # 实现前向传播\n",
    "\n",
    "    def _forward_impl(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.features(x)  # 卷积层特征提取\n",
    "        out = self.map(out)  # 映射层特征提取\n",
    "        out = self.reconstruction(out)  # 重构层进行图像重建\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _initialize_weights(self) -> None:\n",
    "        # 初始化所有卷积层的权重和偏置\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.normal_(module.weight.data, 0.0,\n",
    "                                math.sqrt(2 / (module.out_channels * module.weight.data[0][0].numel())))\n",
    "                nn.init.zeros_(module.bias.data)\n",
    "\n",
    "        # 初始化重构层的权重和偏置\n",
    "        nn.init.normal_(self.reconstruction.weight.data, 0.0, 0.001)\n",
    "        nn.init.zeros_(self.reconstruction.bias.data)\n",
    "\n",
    "# 将BGR格式的张量转换为YCbCr格式的张量.如果only_use_y_channel为True，则仅使用Y通道；否则，使用Y、Cb、Cr三个通道。该函数返回一个PyTorch张量。\n",
    "def bgr2ycbcr_torch(tensor: torch.Tensor, only_use_y_channel: bool) -> torch.Tensor:\n",
    "    if only_use_y_channel:\n",
    "        weight = torch.Tensor([[24.966], [128.553], [65.481]]).to(tensor)\n",
    "        tensor = torch.matmul(tensor.permute(0, 2, 3, 1), weight).permute(0, 3, 1, 2) + 16.0\n",
    "    else:\n",
    "        weight = torch.Tensor([[24.966, 112.0, -18.214],\n",
    "                               [128.553, -74.203, -93.786],\n",
    "                               [65.481, -37.797, 112.0]]).to(tensor)\n",
    "        bias = torch.Tensor([16, 128, 128]).view(1, 3, 1, 1).to(tensor)\n",
    "        tensor = torch.matmul(tensor.permute(0, 2, 3, 1), weight).permute(0, 3, 1, 2) + bias\n",
    "    tensor /= 255.\n",
    "    return tensor\n",
    "\n",
    "# 将YCbCr格式的NumPy数组转换为RGB格式的NumPy数组。\n",
    "def ycbcr2rgb(image: np.ndarray) -> np.ndarray:\n",
    "    image_dtype = image.dtype\n",
    "    image *= 255.\n",
    "    image = np.matmul(image, [[0.00456621, 0.00456621, 0.00456621],\n",
    "                              [0, -0.00153632, 0.00791071],\n",
    "                              [0.00625893, -0.00318811, 0]]) * 255.0 + [-222.921, 135.576, -276.836]\n",
    "\n",
    "    image /= 255.\n",
    "    image = image.astype(image_dtype)\n",
    "    return image\n",
    "\n",
    "# 将NumPy数组转换为PyTorch张量。如果range_norm为True，则将像素值从[0,1]范围转换为[-1,1]范围；如果half为True，则将数据类型从torch.float32转换为torch.half。\n",
    "def image2tensor(image: np.ndarray, range_norm: bool, half: bool) -> torch.Tensor:\n",
    "    tensor = F.to_tensor(image)\n",
    "    # Scale the image data from [0, 1] to [-1, 1]\n",
    "    if range_norm:\n",
    "        tensor = tensor.mul(2.0).sub(1.0)\n",
    "    # Convert torch.float32 image data type to torch.half image data type\n",
    "    if half:\n",
    "        tensor = tensor.half()\n",
    "    return tensor\n",
    "\n",
    "# 将BGR格式的NumPy数组转换为YCbCr格式的NumPy数组。如果only_use_y_channel为True，则仅使用Y通道；否则，使用Y、Cb、Cr三个通道。\n",
    "def bgr2ycbcr(image: np.ndarray, only_use_y_channel: bool) -> np.ndarray:\n",
    "    if only_use_y_channel:\n",
    "        image = np.dot(image, [24.966, 128.553, 65.481]) + 16.0\n",
    "    else:\n",
    "        image = np.matmul(image, [[24.966, 112.0, -18.214], [128.553, -74.203, -93.786], [65.481, -37.797, 112.0]]) + [\n",
    "            16, 128, 128]\n",
    "\n",
    "    image /= 255.\n",
    "    image = image.astype(np.float32)\n",
    "    return image\n",
    "\n",
    "# 将YCbCr格式的NumPy数组转换为BGR格式的NumPy数组。\n",
    "def ycbcr2bgr(image: np.ndarray) -> np.ndarray:\n",
    "    image_dtype = image.dtype\n",
    "    image *= 255.\n",
    "    image = np.matmul(image, [[0.00456621, 0.00456621, 0.00456621],\n",
    "                              [0.00791071, -0.00153632, 0],\n",
    "                              [0, -0.00318811, 0.00625893]]) * 255.0 + [-276.836, 135.576, -222.921]\n",
    "\n",
    "    image /= 255.\n",
    "    image = image.astype(image_dtype)\n",
    "    return image\n",
    "\n",
    "# 将PyTorch张量转换为NumPy数组。\n",
    "# 如果range_norm为True，则将像素值从[-1,1]范围转换为[0,1]范围；\n",
    "# 如果half为True，则将数据类型从torch.float32转换为torch.half。\n",
    "def tensor2image(tensor: torch.Tensor, range_norm: bool, half: bool):\n",
    "    if range_norm:\n",
    "        tensor = tensor.add(1.0).div(2.0)\n",
    "    if half:\n",
    "        tensor = tensor.half()\n",
    "    image = tensor.squeeze(0).permute(1, 2, 0).mul(255).clamp(0, 255).cpu().numpy().astype(\"uint8\")\n",
    "    return image\n",
    "\n",
    "# 计算两张图像的峰值信噪比（PSNR）。该函数使用PyTorch张量进行计算。\n",
    "def psnr(img1, img2):\n",
    "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    # 设置超参数和文件路径\n",
    "    lr_dir = f\"./data/Set5\"  # 低分辨率图像路径\n",
    "    hr_dir = f\"./data/Set5\"  # 高分辨率图像路径\n",
    "    device = torch.device(\"cuda\", 0)  # 使用GPU训练\n",
    "    upscale_factor = 4  # 放大倍数\n",
    "    model_path = './srcnn_model/srcnn_x4-T91-7c460643.pth.tar'  # 模型文件路径\n",
    "    psnr_metrics_all = 0.0  # PSNR指标累计值\n",
    "    ssim_metrics_all = 0.0  # SSIM指标累计值\n",
    "\n",
    "    # 创建模型实例\n",
    "    model = SRCNN().to(device=device, memory_format=torch.channels_last)\n",
    "\n",
    "    # 加载预训练的模型\n",
    "    checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    # 创建输出结果的文件夹\n",
    "    results_dir = os.path.join(\"srcnn_results\")\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "\n",
    "    # 将模型设置为评估模式，并使用半精度浮点数进行推理\n",
    "    model.eval()\n",
    "    model.half()\n",
    "\n",
    "    # 初始化PSNR和SSIM指标\n",
    "    psnr_metrics = 0.0\n",
    "    ssim_metrics = 0.0\n",
    "\n",
    "    # 对所有图像进行测试\n",
    "    file_names = natsorted(os.listdir(lr_dir))\n",
    "    total_files = len(file_names)\n",
    "    for index in range(total_files):\n",
    "        # 读取低分辨率图像、高分辨率图像和输出超分辨率图像的路径\n",
    "        lr_image_path = os.path.join(lr_dir, file_names[index])\n",
    "        sr_image_path = os.path.join(results_dir, f'super_resolution_{file_names[index]}')\n",
    "        hr_image_path = os.path.join(hr_dir, file_names[index])\n",
    "\n",
    "        # 打印当前处理的图像路径\n",
    "        print(f\"正在处理 `{os.path.abspath(lr_image_path)}`...\")\n",
    "\n",
    "        # 读取高分辨率图像并将像素值归一化到[0, 1]范围内\n",
    "        hr_image = cv2.imread(hr_image_path, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.0\n",
    "\n",
    "        # 读取低分辨率图像并进行双三次插值\n",
    "        lr_img = Image.open(lr_image_path)\n",
    "        size = np.min(lr_img.size)\n",
    "        downscale = transforms.Resize(int(size / 4), interpolation=Image.BICUBIC)\n",
    "        upscale = transforms.Resize(int(size), interpolation=Image.BICUBIC)\n",
    "        lr_img = downscale(lr_img)\n",
    "        lr_img = upscale(lr_img)\n",
    "\n",
    "        # 将低分辨率图像转换为numpy数组，并将像素值缩放到[0,1]范围内\n",
    "        lr_image = np.array(lr_img).astype(np.float32) / 255.0\n",
    "\n",
    "        # 将RGB图像转换为BGR图像\n",
    "        lr_image = cv2.cvtColor(lr_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 保存高分辨率图像和低分辨率图像\n",
    "        cv2.imwrite(os.path.join(results_dir, f'GroundTruth_{file_names[index]}'), hr_image * 255.0)\n",
    "        cv2.imwrite(os.path.join(results_dir, f'subsample_{file_names[index]}'), lr_image * 255.0)\n",
    "\n",
    "        # 将低分辨率BGR图像转换为YCbCr图像，并返回Y通道\n",
    "        lr_y_image = bgr2ycbcr(lr_image, True)\n",
    "\n",
    "        # 将高分辨率BGR图像转换为YCbCr图像，并返回Y通道\n",
    "        hr_y_image = bgr2ycbcr(hr_image, True)\n",
    "\n",
    "        # 将高分辨率BGR图像转换为YCbCr图像，并分离出Cb和Cr通道\n",
    "        hr_ycbcr_image = bgr2ycbcr(hr_image, False)\n",
    "        _, hr_cb_image, hr_cr_image = cv2.split(hr_ycbcr_image)\n",
    "\n",
    "        # 将Y通道图像转换为PyTorch张量，并将其添加一个批次维度\n",
    "        lr_y_tensor = image2tensor(lr_y_image, False, True).unsqueeze_(0)\n",
    "        hr_y_tensor = image2tensor(hr_y_image, False, True).unsqueeze_(0)\n",
    "\n",
    "        # 将张量移动到指定的设备，使用通道最后内存格式，并启用非阻塞式传输\n",
    "        lr_y_tensor = lr_y_tensor.to(device=device, memory_format=torch.channels_last, non_blocking=True)\n",
    "        hr_y_tensor = hr_y_tensor.to(device=device, memory_format=torch.channels_last, non_blocking=True)\n",
    "\n",
    "        # 使用模型生成超分辨率图像，将像素值裁剪到[0,1]范围内\n",
    "        with torch.no_grad():\n",
    "            sr_y_tensor = model(lr_y_tensor).clamp_(0, 1.0)\n",
    "        sr_y_image = tensor2image(sr_y_tensor, False, True)\n",
    "        sr_y_image = sr_y_image.astype(np.float32) / 255.0\n",
    "\n",
    "        # 将生成的Y通道图像与原始Cb和Cr通道合并为YCbCr图像\n",
    "        sr_ycbcr_image = cv2.merge([sr_y_image, hr_cb_image, hr_cr_image])\n",
    "\n",
    "        # 将YCbCr图像转换为BGR图像\n",
    "        sr_image = ycbcr2bgr(sr_ycbcr_image)\n",
    "\n",
    "        # 将原始Y通道图像转换为numpy数组，并将像素值缩放到[0,1]范围内\n",
    "        hr_y_image = tensor2image(hr_y_tensor, False, True)\n",
    "        hr_y_image = hr_y_image.astype(np.float32) / 255.0\n",
    "\n",
    "        # 计算超分辨率图像的PSNR和SSIM指标\n",
    "        psnr_metrics = psnr(sr_y_tensor, hr_y_tensor).item()\n",
    "        print(\"sr_y_image\", sr_y_image.shape)\n",
    "        print(\"hr_y_image\", hr_y_image.shape)\n",
    "        ssim_metrics = structural_similarity(sr_y_image, hr_y_image, win_size=7, gaussian_weights=True,\n",
    "                                             multichannel=True, data_range=1.0, K1=0.01, K2=0.03, sigma=1.5)\n",
    "        # 将所有图像的PSNR和SSIM指标加起来，计算平均值\n",
    "        psnr_metrics_all += psnr_metrics\n",
    "        ssim_metrics_all += ssim_metrics\n",
    "        # 将PSNR和SSIM指标以文字形式添加到SR图像上，并保存图像\n",
    "        text = 'psnr:' + str(round(float(psnr_metrics), 3)) + ' ssim:' + str(ssim_metrics)\n",
    "        cv2.putText(sr_image, text, (40, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 1)\n",
    "        # 打印每张图像的PSNR和SSIM指标\n",
    "        print(file_names[index], f' psnr:{psnr_metrics}')\n",
    "        print(file_names[index], f' ssim:{ssim_metrics}')\n",
    "        cv2.imwrite(sr_image_path, sr_image * 255.0)\n",
    "    avg_psnr = 100 if psnr_metrics_all / total_files > 100 else psnr_metrics_all / total_files\n",
    "    avg_ssim = 1 if ssim_metrics_all / total_files > 1 else ssim_metrics_all / total_files\n",
    "    print(f\"PSNR: {avg_psnr:4.2f} [dB]\\n\"\n",
    "          f\"SSIM: {avg_ssim:4.4f} [u]\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1909b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
